{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Prmeira parte do execrício foi para predizer uma mesma característica com diferentes featurizers\n",
    "- Base: Elastic Tensor\n",
    "- Característica para prever: K_VRH (escolha aleatória) - Average of K_Reuss and K_Voigt (propriedades elásticas)\n",
    "- featurizers (baseado na estrutura): CoulomMatrix (mais comum), ElementProperty\n",
    "- Metrica: Linear Regression\n",
    "\n",
    "Nesta segunda parte continuo com:\n",
    "- Testar outros métodos de regressão\n",
    "- Testar com featurizer do paper Hirn et al; 2016 Quantum Energy Regression using Scattering Transforms\n",
    "- Testar outras bases de dado\n",
    "- Melhoria no código e implantação de log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luis/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:58: FutureWarning:\n",
      "\n",
      "Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6df4325184ad481e924617f8102c2d0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='CoulombMatrix', max=1123), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luis/anaconda3/lib/python3.6/site-packages/matminer/featurizers/structure.py:618: ComplexWarning:\n",
      "\n",
      "Casting complex values to real discards the imaginary part\n",
      "\n",
      "/home/luis/anaconda3/lib/python3.6/site-packages/matminer/featurizers/structure.py:618: ComplexWarning:\n",
      "\n",
      "Casting complex values to real discards the imaginary part\n",
      "\n",
      "/home/luis/anaconda3/lib/python3.6/site-packages/matminer/featurizers/structure.py:618: ComplexWarning:\n",
      "\n",
      "Casting complex values to real discards the imaginary part\n",
      "\n",
      "/home/luis/anaconda3/lib/python3.6/site-packages/matminer/featurizers/structure.py:618: ComplexWarning:\n",
      "\n",
      "Casting complex values to real discards the imaginary part\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a4add80996f44cf89607336417a5cc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='StrToComposition', max=1123), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34ffb2024035479bb4f89424e2164bc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='ElementProperty', max=1123), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finish!\n"
     ]
    }
   ],
   "source": [
    "###########################################################\n",
    "# Célula 1\n",
    "# Criação das bases em CSV, para facilitar meus estudos equnato estiver offline\n",
    "#############################################################\n",
    "\n",
    "#Importação dos módulos desta célula de código\n",
    "from matminer.datasets.convenience_loaders import load_elastic_tensor\n",
    "from matminer.featurizers.structure import CoulombMatrix\n",
    "from matminer.featurizers.conversions import StrToComposition\n",
    "from matminer.featurizers.composition import ElementProperty\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "print(\"Start!\")\n",
    "\n",
    "#marca inicio dete bloco\n",
    "t1 = datetime.now()\n",
    "\n",
    "#Criação e configuração do log\n",
    "log = logging.getLogger('Ex2-2')\n",
    "log.setLevel(logging.DEBUG)\n",
    "fh = logging.FileHandler('/home/luis/Downloads/Ex2-2.log')\n",
    "fh.setLevel(logging.DEBUG)\n",
    "fh.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s : %(message)s'))\n",
    "log.addHandler(fh)\n",
    "\n",
    "#####################################################################\n",
    "# Criação dos dados de trino e teste com a base Elastic Tensor\n",
    "#####################################################################\n",
    "log.info(\"Start!\")\n",
    "#obter os dados do elastic tensor e remover colunas não utilizadas\n",
    "df = load_elastic_tensor()  # loads dataset in a pandas DataFrame object\n",
    "log.info(\"Terminada leitura do Elastic Tensor.\")\n",
    "#removendo linhas com mais de 30 átomos (Nsites > 30)\n",
    "df = df[df.nsites<=30]\n",
    "log.info(\"Removidas as linhas com nsites > 30.\")\n",
    "df.to_csv(\"/home/luis/Downloads/elastic_tensor.csv\", index=False)\n",
    "unwanted_columns = [\"volume\", \"nsites\", \"compliance_tensor\", \"elastic_tensor\", \n",
    "                    \"elastic_tensor_original\", \"K_Voigt\", \"G_Voigt\", \"K_Reuss\", \"G_Reuss\", \n",
    "                    \"G_VRH\", 'elastic_anisotropy']\n",
    "df = df.drop(unwanted_columns, axis=1)\n",
    "log.info(\"Removidas colunas que não serão utilizadas.\")\n",
    "\n",
    "#Criação do ndarray \"Y\"\n",
    "y_K_VRH = df['K_VRH'].values\n",
    "log.info(\"Criado o ndarray com os dados para 'Y'\")\n",
    "#Exporta em CSV para facilitar o trabalho quando eu estiver offline.\n",
    "pd.DataFrame(y_K_VRH).to_csv(\"/home/luis/Downloads/y_K_VRH.csv\", index=False) \n",
    "log.info(\"Criado o arquivo y_K_VRH.CSV com os dados para 'Y' para importar nos módulos posteriores.\")\n",
    "log.info(\"Ínicio dos dados de y_K_VRH:\")\n",
    "log.info(pd.DataFrame(y_K_VRH).head())\n",
    "\n",
    "###################################################\n",
    "# Primeiro featurizer: CoulombMatrix\n",
    "###################################################\n",
    "#Criação do dataframe \"X\" com a coulombmatrix\n",
    "X = df['structure'].as_matrix()\n",
    "log.info(\"Criados dados de X como matriz para usar o CoulombMatrix como Flatten\")\n",
    "cm = CoulombMatrix(flatten=True).fit(X)\n",
    "log.info(\"Criada a estrutura da CoulombMatrix com dados de X\")\n",
    "X_CM = cm.featurize_dataframe(df.copy(), \"structure\")\n",
    "log.info(\"Criado um DataFrame X_CM, cópia de X, incluindo os dados da CoulombMatrix \")\n",
    "# exclui demais colunas, para ficar somente os dados da coulombmatrix\n",
    "excluded = [\"K_VRH\", \"formula\", \"material_id\", \n",
    "           \"poisson_ratio\", \"structure\", \"space_group\"]\n",
    "X_CM = X_CM.drop(excluded, axis=1)\n",
    "log.info(\"Excluídas de X_CM as colunas que não serão usadas.\")\n",
    "#Exporta em CSV para facilitar o trabalho quando eu estiver offline.\n",
    "X_CM.to_csv(\"/home/luis/Downloads/X_CM.csv\", index=False) \n",
    "log.info(\"Criado o arquivo X_CM.CSV com os dados de X_CM para importar nos módulos posteriores.\")\n",
    "log.info(\"Início do dataframe com a CoulombMatrix:\")\n",
    "log.info(X_CM.head())\n",
    "\n",
    "# Inclui couna \"composition\" para os próximos featurizers\n",
    "df = StrToComposition().featurize_dataframe(df, \"formula\")\n",
    "log.info(\"Incluido no Dataframe inicial os dados de Composition (feturizer), para utilização na criação do ElementProperty\")\n",
    "\n",
    "###################################################\n",
    "# Segundo featurizer: ElementProperty\n",
    "###################################################\n",
    "#Criação do dataframe \"X\" com as informações de EwaldEnergy\n",
    "ep = ElementProperty.from_preset(preset_name=\"magpie\")\n",
    "log.info(\"Criado elemento para featurizer ElementProperty com as informações de EwaldEnergy\")\n",
    "X_EP = ep.featurize_dataframe(df.copy(), col_id=\"composition\")  # Inlui a coluna \"composition\"\n",
    "log.info(\"Criado um DataFrame X_EP, cópia de X, incluindo os dados de ElementProperty\")\n",
    "#exclui demais colunas, para ficar somente os dados de ElementProperty\n",
    "excluded = [\"K_VRH\", \"formula\", \"material_id\", \n",
    "            \"poisson_ratio\", \"structure\", \"space_group\", \"composition\"]\n",
    "X_EP = X_EP.drop(excluded, axis=1)\n",
    "log.info(\"Excluídas de X_EP as colunas que não serão usadas.\")\n",
    "#Exporta em CSV para facilitar o trabalho quando eu estiver offline.\n",
    "X_EP.to_csv(\"/home/luis/Downloads/X_EP.csv\", index=False) \n",
    "log.info(\"Criado o arquivo X_EP.CSV com os dados de X_EP para importar nos módulos posteriores.\")\n",
    "log.info(\"Início do dataframe com o ElementProperty\")\n",
    "log.info(X_EP.head())\n",
    "\n",
    "#maca fim do bloco e tempo gasto\n",
    "log.info(\"Finish!\")\n",
    "log.info(\"Tempo gasto %s\" % (datetime.now() - t1))\n",
    "\n",
    "print(\"Finish!\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start!\n",
      "-----------------------------------------------------------\n",
      "\n",
      "# Avaliando: Estimator=SVR, Featurizer=CoulombMatrix e Score = r2\n",
      "\n",
      "\n",
      "Score com os dados de treino:\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   8 | elapsed: 13.2min remaining: 22.0min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   8 | elapsed: 13.2min remaining:  7.9min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-ae0aca458258>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeaturizer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train_X\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeaturizer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train_y\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Concluído o 'fit' com os dados de treino.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "###########################################################\n",
    "# Célula 2\n",
    "# Predição com estimator KernelRidge e CoulombMatrix \n",
    "#############################################################\n",
    "\n",
    "# evitando as mensagens dw warning\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    " \n",
    "\n",
    "#Importação dos módulos desta célula de código\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.svm import SVR\n",
    "from matplotlib import pyplot\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy\n",
    "import logging\n",
    "\n",
    "print(\"Start!\")\n",
    "\n",
    "#marca inicio dete bloco\n",
    "t1 = datetime.now()\n",
    "\n",
    "#Criação e configuração do log\n",
    "log = logging.getLogger('Ex2-2')\n",
    "log.setLevel(logging.INFO) # ou logging.DEBUG\n",
    "fh = logging.FileHandler('/home/luis/Downloads/Ex2-2-Celula2.log')\n",
    "fh.setLevel(logging.INFO) # ou logging.DEBUG\n",
    "fh.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s : %(message)s'))\n",
    "log.addHandler(fh)\n",
    "\n",
    "\n",
    "# importação dos CSVs para os Dataframes\n",
    "log.info(\"Start!\")\n",
    "y_K_VRH = pd.read_csv(\"/home/luis/Downloads/y_K_VRH.csv\")\n",
    "log.info(\"Carregado o dataframe com y_K_VRH\")\n",
    "log.info(y_K_VRH.columns)\n",
    "log.info(y_K_VRH.describe())\n",
    "X_EP = pd.read_csv(\"/home/luis/Downloads/X_EP.csv\")\n",
    "log.info(\"Carregado o dataframe com X_EP\")\n",
    "log.info(X_EP.columns)\n",
    "log.info(X_EP.describe())\n",
    "X_CM = pd.read_csv(\"/home/luis/Downloads/X_CM.csv\")\n",
    "log.info(\"Carregado o dataframe com y_X_CM\")\n",
    "log.info(X_CM.columns)\n",
    "log.info(X_CM.describe())\n",
    "\n",
    "\n",
    "#Separação dos dados de treino e teste\n",
    "train_X_CM, val_X_CM, train_y_CM, val_y_CM = train_test_split(X_CM, y_K_VRH, random_state=1)\n",
    "log.info(\"Criados os dados de train e test para o Dtaframe com CoulombMatrix: X_CM\")\n",
    "log.info(train_X_CM.describe())\n",
    "log.info(val_X_CM.describe())\n",
    "train_X_EP, val_X_EP, train_y_EP, val_y_EP = train_test_split(X_EP, y_K_VRH, random_state=1)\n",
    "log.info(\"Criados os dados de train e test para o Dtaframe com ElementProperty: X_EP\")\n",
    "log.info(train_X_EP.describe())\n",
    "log.info(val_X_EP.describe())\n",
    "\n",
    "#criação de lista com dados de treino e teste (tentar tirar colchetes)\n",
    "featurizers = [{\"featurizer\":\"CoulombMatrix\",\n",
    "         \"train_X\": train_X_CM,\n",
    "         \"train_y\": train_y_CM,\n",
    "         \"val_X\": val_X_CM,\n",
    "         \"val_y\": val_y_CM},\n",
    "        {\"featurizer\":\"ElementProperty\",\n",
    "         \"train_X\": train_X_EP,\n",
    "         \"train_y\": train_y_EP,\n",
    "         \"val_X\": val_X_EP,\n",
    "         \"val_y\": val_y_EP}\n",
    "       ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Lista de Kernels que serão utilizados e respectivas faixas de parâmetros para avaliação\n",
    "# Os parâmetros utilizados são os disponíveis para os estimators. Este parâmentros podem ser \n",
    "# obtidos com a função get_params() de cada estimator\n",
    "# Para os que vou sar neste estudo, são:\n",
    "# KerlRidge -> \n",
    "# {alpha': 1, 'coef0': 1, 'degree': 3, 'gamma': None, 'kernel': 'linear', 'kernel_params': None}\n",
    "# SVR ->\n",
    "# {'C': 1.0, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'auto_deprecated', \n",
    "# 'kernel': 'rbf', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
    "# Os valores iniciais de cada parâmetros foram definido em um range específico e depois \n",
    "# serão ajustados estes ranges conforme os resultados:\n",
    "# alpha: Fibonacci de 1 a 5\n",
    "# gamma: 0.1, 0.3, 0.5, 0.8\n",
    "# degree: Fibonacci de 1 a 5\n",
    "# coef0: 0.1, 0.3, 0.5, 0.8\n",
    "param_KR = [{'kernel': ['linear'], \n",
    "                     'alpha': [1, 2, 3, 5]}, \n",
    "                    {'kernel': ['rbf'], \n",
    "                     'alpha': [1, 2, 3, 5], \n",
    "                     'gamma': [0.1, 0.3, 0.5, 0.8]},  \n",
    "                     {'kernel': ['polynomial'], \n",
    "                     'alpha': [1, 2, 3, 5], \n",
    "                     'gamma': [0.1, 0.3, 0.5, 0.8],\n",
    "                     'degree': [1, 2, 3, 5],\n",
    "                     'coef0': [0.1, 0.3, 0.5, 0.8]},\n",
    "                    {'kernel': ['cosine'], \n",
    "                     'alpha': [1, 2, 3, 5]}, \n",
    "                    {'kernel': ['laplacian'], \n",
    "                     'alpha': [1, 2, 3, 5], \n",
    "                     'gamma': [0.1, 0.3, 0.5, 0.8]}\n",
    "                    ]\n",
    "param_SVR = [{'kernel': ['linear'],  #o kernel linear só com um parametro demrou 20mn. para executar \n",
    "                     'C': [1]} #, 2, 3, 5]}, \n",
    "                   # {'kernel': ['rbf'], \n",
    "                   #  'C': [1, 2, 3, 5], \n",
    "                   #  'gamma': [0.1, 0.3, 0.5, 0.8]},  \n",
    "                   #  {'kernel': ['polynomial'], \n",
    "                   #  'C': [1, 2, 3, 5], \n",
    "                   #  'gamma': [0.1, 0.3, 0.5, 0.8],\n",
    "                   #  'degree': [1, 2, 3, 5],\n",
    "                   #  'coef0': [0.1, 0.3, 0.5, 0.8]},\n",
    "                   # {'kernel': ['cosine'], \n",
    "                   #  'C': [1, 2, 3, 5]}, \n",
    "                   # {'kernel': ['laplacian'], \n",
    "                   #  'C': [1, 2, 3, 5], \n",
    "                   #  'gamma': [0.1, 0.3, 0.5, 0.8]}\n",
    "                    ]\n",
    "estimators = [{\"name\": \"KernelRidge\",\n",
    "               \"estimator\": KernelRidge(),\n",
    "              \"parameters\": param_KR},\n",
    "              {\"name\": \"SVR\",\n",
    "              \"estimator\": SVR(),\n",
    "             \"parameters\": param_SVR},\n",
    "          ]\n",
    "log.info(\"Criados os parâmetros para os estimators\")\n",
    "log.info(estimators)\n",
    "\n",
    "# scores para avaliação de kernels lineares\n",
    "# https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics.pairwise\n",
    "scores = ['r2', 'neg_mean_absolute_error',  'neg_mean_squared_error']\n",
    "log.info(\"Scores para o GridSearchCV:\")\n",
    "log.info(scores)\n",
    "\n",
    "#laço para avaliação dos estimators\n",
    "for estimator in estimators:\n",
    "    #laço para avaliação dos diverso featurizers\n",
    "    for featurizer in featurizers:\n",
    "        # esta lista de scores pode ser passada direta para o parametro scoring do GridSearchCV, \n",
    "        #mas foi usada em um laço de \"for\" para melhor clareza no log de execução\n",
    "        for score in scores: \n",
    "    \n",
    "            print(\"-----------------------------------------------------------\")\n",
    "            print()\n",
    "            print(\"# Avaliando: Estimator=%s, Featurizer=%s e Score = %s\" % \n",
    "                  (estimator[\"name\"], featurizer[\"featurizer\"], score))\n",
    "            print()\n",
    "            log.info(\"# Avaliando: Estimator=%s, Featurizer=%s e Score = %s\" % \n",
    "                  (estimator[\"name\"], featurizer[\"featurizer\"], score))\n",
    "            \n",
    "            clf = GridSearchCV(estimator[\"estimator\"], estimator[\"parameters\"], cv=2, verbose=5,  \n",
    "                       scoring='%s' % score, n_jobs=-1)\n",
    "            log.info(\"Criado o objeto GridSearchCV:\")\n",
    "            log.info(clf)\n",
    "\n",
    "            print()\n",
    "            print(\"Score com os dados de treino:\")\n",
    "            log.info(\"Score com os dados de treino:\")\n",
    "\n",
    "           \n",
    "            clf.fit(featurizer[\"train_X\"], featurizer[\"train_y\"])\n",
    "            log.info(\"Concluído o 'fit' com os dados de treino.\")\n",
    "\n",
    "            log.info(\"Melhores parâmetros encontrados:\")\n",
    "            log.info(clf.best_params_)\n",
    "            print(\"Melhores parâmetros encontrados:\")\n",
    "            print(clf.best_params_)\n",
    "    \n",
    "            means = clf.cv_results_['mean_test_score']\n",
    "            stds = clf.cv_results_['std_test_score']\n",
    "            for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "                #print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "                #      % (mean, std * 2, params))\n",
    "                log.info(\"%0.3f (+/-%0.03f) for %r\"\n",
    "                      % (mean, std * 2, params))\n",
    "\n",
    "            print()\n",
    "    \n",
    "log.info(\"Finish!\")\n",
    "print(\"Finish!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
